{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from os.path import basename\n",
    "from tqdm import tqdm\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autocropping images to minimize unannotated extent \n",
    "\n",
    "with open(\"hotspots_labeled.json\", \"r\") as inf:\n",
    "    hotspots = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"signs.txt\", \"r\") as sgns:\n",
    "    signs = [sign.strip() for sign in sgns.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5010/5010 [33:00<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "autocropped_hotspots = []\n",
    "\n",
    "outfolder = \"/local/ecw/deepscribe-detectron/data/images_cropped\"\n",
    "annotated = \"/local/ecw/deepscribe-detectron/data/images_annotated\"\n",
    "\n",
    "for hotspot in tqdm(hotspots):\n",
    "    # don't keep if there's only one sign!\n",
    "    # TODO: check thresholds here. \n",
    "\n",
    "    if len(hotspot[\"annotations\"]) > 1:\n",
    "        new_hotspot = deepcopy(hotspot)\n",
    "\n",
    "        points = [anno[\"bbox\"] for anno in hotspot[\"annotations\"]]\n",
    "        \n",
    "        # dealing with negative-valued coordinates\n",
    "        min_x0 = int(max(0, min([pt[0] for pt in points])))\n",
    "        max_x1 = int(max([pt[2] for pt in points]))\n",
    "\n",
    "        min_y0 = int(max(0, min([pt[1] for pt in points])))\n",
    "        max_y1 = int(max([pt[3] for pt in points]))\n",
    "\n",
    "        img = cv2.imread(hotspot[\"file_name\"])\n",
    "\n",
    "\n",
    "        cropped = img[min_y0:max_y1, min_x0:max_x1, :]\n",
    "\n",
    "\n",
    "        # adjust points - new origin is min_x0, min_y0\n",
    "\n",
    "\n",
    "        new_hotspot[\"height\"] = cropped.shape[0]\n",
    "        new_hotspot[\"width\"] = cropped.shape[1]\n",
    "        new_hotspot[\"file_name\"] = basename(hotspot[\"file_name\"])\n",
    "        new_hotspot[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "\n",
    "        for anno in new_hotspot[\"annotations\"]:\n",
    "            old_bbox = anno[\"bbox\"]\n",
    "\n",
    "            anno[\"bbox\"] = [\n",
    "                max(0, old_bbox[0]) - min_x0,\n",
    "                old_bbox[1] - min_y0,\n",
    "                old_bbox[2] - min_x0,\n",
    "                old_bbox[3] - min_y0,\n",
    "            ]\n",
    "\n",
    "        \n",
    "\n",
    "        cv2.imwrite(outfolder + \"/\" + new_hotspot[\"file_name\"], cropped)\n",
    "        autocropped_hotspots.append(new_hotspot)\n",
    "        visualizer = Visualizer(cropped[:, :, ::-1], scale=0.5, metadata={\"thing_classes\": signs})\n",
    "        out = visualizer.draw_dataset_dict(new_hotspot)\n",
    "        cv2.imwrite(annotated + \"/\" + basename(hotspot[\"file_name\"]), out.get_image()[:, :, ::-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/hotspots_all.json\", \"w\") as outf:\n",
    "    json.dump(autocropped_hotspots, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# produce train-test-validation splits\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio=0.1\n",
    "\n",
    "hotspots_train, hotspots_test = train_test_split(autocropped_hotspots, test_size=1 - train_ratio)\n",
    "\n",
    "hotspots_test, hotspots_val = train_test_split(hotspots_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "with open(\"data/hotspots_train.json\", \"w\") as outf:\n",
    "    json.dump(hotspots_train, outf)\n",
    "\n",
    "with open(\"data/hotspots_val.json\", \"w\") as outf:\n",
    "    json.dump(hotspots_val, outf)\n",
    "\n",
    "with open(\"data/hotspots_test.json\", \"w\") as outf:\n",
    "    json.dump(hotspots_test, outf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hotspots(entry: dict) -> Tuple[List[np.ndarray], List[int]]:\n",
    "\n",
    "    #load image \n",
    "    img = cv2.imread(outfolder +\"/\" + entry[\"file_name\"])\n",
    "\n",
    "    # get all bboxes\n",
    "\n",
    "    bboxes = [annotation[\"bbox\"] for annotation in entry[\"annotations\"]]\n",
    "    category_ids = [annotation[\"category_id\"] for annotation in entry[\"annotations\"]]\n",
    "\n",
    "    hotspots = []\n",
    "    for bbox in bboxes:\n",
    "        hotspot = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        hotspots.append(hotspot)\n",
    "\n",
    "    return hotspots, category_ids\n",
    "\n",
    "def save_hotspots(dataset: List[dict], outfolder: str):\n",
    "\n",
    "    for entry in tqdm(dataset):\n",
    "        hotspots, category_ids = extract_hotspots(entry)\n",
    "        for i, (hotspot, cat_id) in enumerate(zip(hotspots, category_ids)):\n",
    "            cv2.imwrite(f\"{outfolder}/{Path(entry['file_name']).stem}_{i}_{cat_id}.jpg\", hotspot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3740/3740 [05:02<00:00, 12.38it/s]\n",
      "100%|██████████| 748/748 [01:00<00:00, 12.32it/s]\n",
      "100%|██████████| 499/499 [00:40<00:00, 12.41it/s]\n"
     ]
    }
   ],
   "source": [
    "save_hotspots(hotspots_train, \"/local/ecw/deepscribe-detectron/data/hotspots/train\")\n",
    "save_hotspots(hotspots_test, \"/local/ecw/deepscribe-detectron/data/hotspots/test\")\n",
    "save_hotspots(hotspots_val, \"/local/ecw/deepscribe-detectron/data/hotspots/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ochre_to_xywh(bbox: List) -> List:\n",
    "    # ochre data provided in  [top left x position, top left y position, bottom right x position, bottom right y position].\n",
    "    # coco format is [top left x position, top left y position, width, height].\n",
    "\n",
    "    new_bbox = deepcopy(bbox)\n",
    "    new_bbox[2] -= new_bbox[0]\n",
    "    new_bbox[3] -= new_bbox[1]\n",
    "    return new_bbox\n",
    "\n",
    "def detectron_to_coco(detectron_dataset: List[dict], sign_list: List[str]):\n",
    "    coco_json = {\"images\": [], \"annotations\": []}\n",
    "\n",
    "    # add categories\n",
    "    coco_json[\"categories\"] = [{\"id\": i, \"name\": cat} for i, cat in enumerate(sign_list)]\n",
    "\n",
    "    annotation_ids = 0 \n",
    "\n",
    "    for i, entry in enumerate(tqdm(detectron_dataset)):\n",
    "        # get image data\n",
    "        # assigning image IDs here\n",
    "        image_data = {\"file_name\": entry[\"file_name\"], \"height\":entry[\"height\"], \"width\": entry[\"width\"], \"id\": i}\n",
    "        coco_json[\"images\"].append(image_data)\n",
    "        # collecting annotations\n",
    "        for annotation in entry[\"annotations\"]:\n",
    "\n",
    "            coco_bbox = ochre_to_xywh(annotation[\"bbox\"])\n",
    "            coco_annotation = {\"image_id\": i, \n",
    "                                \"bbox\": coco_bbox, \n",
    "                                \"category_id\": annotation[\"category_id\"],\n",
    "                                \"iscrowd\": 0,\n",
    "                                \"id\": annotation_ids,\n",
    "                                \"area\": coco_bbox[2]*coco_bbox[3]}\n",
    "            coco_json[\"annotations\"].append(coco_annotation)\n",
    "            annotation_ids += 1\n",
    "\n",
    "    return coco_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3740/3740 [00:01<00:00, 2411.25it/s]\n",
      "100%|██████████| 499/499 [00:00<00:00, 4792.06it/s]\n",
      "100%|██████████| 748/748 [00:00<00:00, 4811.58it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"data/hotspots_train_coco.json\", \"w\") as outf:\n",
    "    json.dump(detectron_to_coco(hotspots_train, signs), outf)\n",
    "\n",
    "with open(\"data/hotspots_val_coco.json\", \"w\") as outf:\n",
    "    json.dump(detectron_to_coco(hotspots_val, signs), outf)\n",
    "\n",
    "with open(\"data/hotspots_test_coco.json\", \"w\") as outf:\n",
    "    json.dump(detectron_to_coco(hotspots_test, signs), outf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}