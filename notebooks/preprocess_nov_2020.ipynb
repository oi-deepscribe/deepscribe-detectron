{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37864bit32ffe0830bdc4e16bb70c3d448223acc",
   "display_name": "Python 3.7.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from os.path import basename\n",
    "import shutil\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from typing import Dict, Tuple, List\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../raw_ochre/imagesWithHotspots_nov_2020.txt\", \"r\") as infile:\n",
    "    annotations = [line.strip() for line in infile.readlines() if len(line.strip()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefolder = \"/local/ecw/deepscribe-detectron/archive/images_renamed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "# collecting all signs and readings to assign numerical IDs\n",
    "# counting sign frequencies\n",
    "sign_ids = list()\n",
    "sign_frequencies = list()\n",
    "reading_ids = list()\n",
    "reading_frequencies = list()\n",
    "for anno in annotations:\n",
    "\n",
    "    textname, size, hotspots = anno.split(\":\")\n",
    "\n",
    "    uuid =  textname.split(\"_\")[0]\n",
    "\n",
    "    height, width = [int(val) for val in size.split(\"x\")]\n",
    "\n",
    "    fname = f\"{imagefolder}/{uuid}.jpg\"\n",
    "\n",
    "    assert os.path.exists(fname), f\"image file {fname} does not exist!\"\n",
    "\n",
    "    annos = []\n",
    "\n",
    "    for hotspot in hotspots.split(\";\"):\n",
    "        if len(hotspot) > 0:\n",
    "            classes, coordslist = hotspot.split(\"~\")\n",
    "            # Sandra Schloen, Nov 2019:\n",
    "            #Please note: when I created the new hotspots I labeled them with the signName_signUUID \n",
    "            # so that hotspot cutouts of the same sign would sort together in a folder. Previously when I\n",
    "            #  created this image list I used signUUID_signName, but this time I have swapped them to make\n",
    "            #  the format more consistent with the hotspot labels; that is, the Name now precedes the UUID\n",
    "            #  in this new image list too. Youâ€™ll need to adjust your code accordingly.\n",
    "\n",
    "            sign,reading = [elem.split(\"_\")[0] for elem in classes.split(\"/\")]\n",
    "\n",
    "            # assign the sign and reading ID \n",
    "    \n",
    "            if sign not in sign_ids:\n",
    "                sign_ids.append(sign)\n",
    "                sign_frequencies.append(1)\n",
    "\n",
    "            sign_id = sign_ids.index(sign)\n",
    "            sign_frequencies[sign_id] += 1\n",
    "\n",
    "            if reading not in reading_ids:\n",
    "                reading_ids.append(reading)\n",
    "                reading_frequencies.append(1)\n",
    "\n",
    "            reading_id = reading_ids.index(reading)\n",
    "            reading_frequencies[reading_id] += 1\n",
    "\n",
    "            coords = [float(coord) for coord in coordslist.split(\",\")]\n",
    "            # only 1 category for now - just sign or non-sign\n",
    "            annos.append({\"bbox\": coords, \"bbox_mode\":0, \"sign\":sign, \"reading\": reading, \"sign_id\": sign_id, \"reading_id\": reading_id, \"category_id\": sign_id})\n",
    "\n",
    "    dataset.append({\"file_name\":fname, \"height\":height, \"width\":width, \"image_id\": uuid, \"annotations\": annos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/5013 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-72aed688c3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# cv2.imwrite(annotated + \"/\" + basename(hotspot[\"file_name\"]), out.get_image()[:, :, ::-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mvisualizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"thing_classes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"hotspot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_dataset_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_hotspot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhotspots_only\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhotspot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/ecw/miniconda3/envs/detectron/lib/python3.7/site-packages/detectron2/utils/visualizer.py\u001b[0m in \u001b[0;36mdraw_dataset_dict\u001b[0;34m(self, dic)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thing_classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             labels = [\n\u001b[1;32m    533\u001b[0m                 \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"|crowd\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iscrowd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/ecw/miniconda3/envs/detectron/lib/python3.7/site-packages/detectron2/utils/visualizer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thing_classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             labels = [\n\u001b[1;32m    533\u001b[0m                 \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"|crowd\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iscrowd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# crop images to remove \"empty\" space of images\n",
    "autocropped_hotspots = []\n",
    "\n",
    "outfolder = \"/local/ecw/deepscribe-detectron/data_nov_2020/images_cropped\"\n",
    "annotated = \"/local/ecw/deepscribe-detectron/data_nov_2020/images_annotated\"\n",
    "hotspots_only = \"/local/ecw/deepscribe-detectron/data_nov_2020/images_annotated_hotspots\"\n",
    "\n",
    "for hotspot in tqdm(dataset):\n",
    "    # don't keep if there's only one sign!\n",
    "    # TODO: check thresholds here. \n",
    "\n",
    "    if len(hotspot[\"annotations\"]) > 1:\n",
    "        new_hotspot = deepcopy(hotspot)\n",
    "\n",
    "        points = [anno[\"bbox\"] for anno in hotspot[\"annotations\"]]\n",
    "        \n",
    "        # dealing with negative-valued coordinates\n",
    "        min_x0 = int(max(0, min([pt[0] for pt in points])))\n",
    "        max_x1 = int(max([pt[2] for pt in points]))\n",
    "\n",
    "        min_y0 = int(max(0, min([pt[1] for pt in points])))\n",
    "        max_y1 = int(max([pt[3] for pt in points]))\n",
    "\n",
    "        img = cv2.imread(hotspot[\"file_name\"])\n",
    "\n",
    "\n",
    "        cropped = img[min_y0:max_y1, min_x0:max_x1, :]\n",
    "\n",
    "\n",
    "        # adjust points - new origin is min_x0, min_y0\n",
    "\n",
    "\n",
    "        new_hotspot[\"height\"] = cropped.shape[0]\n",
    "        new_hotspot[\"width\"] = cropped.shape[1]\n",
    "        new_hotspot[\"file_name\"] = basename(hotspot[\"file_name\"])\n",
    "        new_hotspot[\"bbox_mode\"] = 0\n",
    "\n",
    "        for anno in new_hotspot[\"annotations\"]:\n",
    "            old_bbox = anno[\"bbox\"]\n",
    "\n",
    "            anno[\"bbox\"] = [\n",
    "                max(0, old_bbox[0]) - min_x0,\n",
    "                old_bbox[1] - min_y0,\n",
    "                old_bbox[2] - min_x0,\n",
    "                old_bbox[3] - min_y0,\n",
    "            ]\n",
    "\n",
    "        \n",
    "\n",
    "        # cv2.imwrite(outfolder + \"/\" + new_hotspot[\"file_name\"], cropped)\n",
    "        # autocropped_hotspots.append(new_hotspot)\n",
    "        # visualizer = Visualizer(cropped[:, :, ::-1], scale=0.5, metadata={\"thing_classes\": sign_ids})\n",
    "        # out = visualizer.draw_dataset_dict(new_hotspot)\n",
    "        # cv2.imwrite(annotated + \"/\" + basename(hotspot[\"file_name\"]), out.get_image()[:, :, ::-1])\n",
    "        visualizer = Visualizer(cropped[:, :, ::-1], scale=0.5, metadata={\"thing_classes\": [\"hotspot\" for sign in sign_ids]})\n",
    "        out = visualizer.draw_dataset_dict(new_hotspot)\n",
    "        cv2.imwrite(hotspots_only + \"/\" + basename(hotspot[\"file_name\"]), out.get_image()[:, :, ::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train-test-val\n",
    "# # produce train-test-validation splits\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio=0.1\n",
    "\n",
    "hotspots_train, hotspots_test = train_test_split(autocropped_hotspots, test_size=1 - train_ratio)\n",
    "\n",
    "hotspots_test, hotspots_val = train_test_split(hotspots_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "with open(\"/local/ecw/deepscribe-detectron/data_nov_2020/hotspots_train.json\", \"w\") as outf:\n",
    "    json.dump(hotspots_train, outf)\n",
    "\n",
    "with open(\"/local/ecw/deepscribe-detectron/data_nov_2020/hotspots_val.json\", \"w\") as outf:\n",
    "    json.dump(hotspots_val, outf)\n",
    "\n",
    "with open(\"/local/ecw/deepscribe-detectron/data_nov_2020/hotspots_test.json\", \"w\") as outf:\n",
    "    json.dump(hotspots_test, outf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sign list to disk\n",
    "\n",
    "signs_df = pd.DataFrame({\"sign\": sign_ids, \"frequency\":sign_frequencies}) \n",
    "\n",
    "signs_df.to_csv(\"/local/ecw/deepscribe-detectron/data_nov_2020/signs_nov_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hotspots(entry: dict) -> Tuple[List[np.ndarray], List[int]]:\n",
    "\n",
    "    #load image \n",
    "    img = cv2.imread(outfolder +\"/\" + entry[\"file_name\"])\n",
    "\n",
    "    # get all bboxes\n",
    "\n",
    "    bboxes = [annotation[\"bbox\"] for annotation in entry[\"annotations\"]]\n",
    "    category_ids = [annotation[\"category_id\"] for annotation in entry[\"annotations\"]]\n",
    "\n",
    "    hotspots = []\n",
    "    for bbox in bboxes:\n",
    "        hotspot = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        hotspots.append(hotspot)\n",
    "\n",
    "    return hotspots, category_ids\n",
    "\n",
    "def save_hotspots(dataset: List[dict], outfolder: str):\n",
    "\n",
    "    os.makedirs(outfolder, exist_ok=True)\n",
    "\n",
    "    for entry in tqdm(dataset):\n",
    "        hotspots, category_ids = extract_hotspots(entry)\n",
    "        for i, (hotspot, cat_id) in enumerate(zip(hotspots, category_ids)):\n",
    "            os.makedirs(f\"{outfolder}/{cat_id}\", exist_ok=True)\n",
    "\n",
    "            cv2.imwrite(f\"{outfolder}/{cat_id}/{Path(entry['file_name']).stem}_{i}_{cat_id}.jpg\", hotspot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3742/3742 [06:18<00:00,  9.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 748/748 [01:26<00:00,  8.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:44<00:00, 11.18it/s]\n"
     ]
    }
   ],
   "source": [
    "save_hotspots(hotspots_train, \"/local/ecw/deepscribe-detectron/data_nov_2020/hotspots/train\")\n",
    "save_hotspots(hotspots_test, \"/local/ecw/deepscribe-detectron/data_nov_2020/hotspots/test\")\n",
    "save_hotspots(hotspots_val, \"/local/ecw/deepscribe-detectron/data_nov_2020/hotspots/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}